---
layout:     post
title:      "CS231n: Linear Classification"
subtitle:   "线性分类笔记"
date:       2016-09-23 15:00
author:     "Jianfei"
header-img: "img/post-bg-lc.jpg"
tags:        [CS231n]
category:   Course
---

## CS231n简介
[Stanford CS231n-Convolutional Neural Networks for Visual Recognition(Winter 2016)](http://cs231n.stanford.edu/)是一门讲述CNN在图像识别和分类中应用的课程，由Prof. Feifei Li授课。它包括两个模块，分别是Neural Networks和Convolutional Neural Networks，课程可用资源为[Course Notes](http://cs231n.github.io/)与[知乎翻译版](https://zhuanlan.zhihu.com/intelligentunit)。另外在Youtube中有完整版的[Lecture Video](https://www.youtube.com/playlist?list=PLLvH2FwAQhnpj1WEB-jHmPuUeQ8mX-XXG)。使用的数据集来自多伦多大学的[Cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html)。

选择这门MOOC来自学，也是想在做其他领域的同时不抛弃原本做过的计算机视觉领域，并将机器学习与神经网络的知识融会贯通，说不定会在自己的领域有新的想法。

前几章铺垫的部分讲述了**Python与numpy库**的基本用法，并简单阐述了**图像分类**这一概念的目标与简单实现方法（KNN）。笔记我将直接从线性分类器开始写起。

### 线性分类
图像分类是从已有的固定标签中选择一个合适的标签给一张新的图像。k-Nearest Neighbor分类器通过比较新图像$I_{test}$与所有训练集${I_{train}}$的距离来判断它的标签。但是k-NN需要将所有的训练数据存储用于比较，存储与计算的复杂度高。

我们需要实现一种新的方法来解决图像分类问题。它包括两个部分：一个是**评分函数(score function)**，是从原始图像到类标的映射；另一个是**损失函数(loss function)**，用来量化预测结果与真实结果的一致性。于是该方法可以被转化为一个**最优化问题**，通过更新评分函数的参数来最小化损失函数的结果。

### 评分函数
评分函数将图像的像素值映射到各个类别的得分，而得分的高低代表了属于该类别的可能性高低。我们假设一个包含很多图像的训练集$x_i \in R^D$，对应一个分类标签$y_i$且$y_i \in 1, ..., K$。这里我们有个$N$训练样本，图像维度为$D$，有$K$种分类标签。在CIFAR-10中，$N=50000$，$D=32\times32\times3$，$K=10$，定义评分函数$f: R^D\\to R^K$。

最简单的概率函数就是线性映射，也就是线性分类器的评分函数：
$$f(x_i,W,b)=Wx_i+b$$
其中$W$被称为权重，$b$被称为偏差向量。输入图像$x_i$被拉长为一个长度为D的列向量。

这样训练后得到的权值矩阵就代表了训练数据给出的分类信息，而不用再保留大量的训练数据。而计算复杂度只是一个矩阵乘法和加法就够了。

<a href="#">
    <img class="img-responsive" src="http://cs231n.github.io/assets/imagemap.jpg" alt="" width="100%"></a>
首先将图像像素拉伸为一个列向量，与W进行矩阵乘，然后得到各个分类的分值。这个过程实际上是在高维空间当中的线性二值分类。线性分类器中的权重矩阵每一行对应着一个分类的模板，而图像不同分类的得分是通过计算图像与模板的内积得到的。模板是通过训练集训练得到的，而内积衡量了距离（相似度）。
<a href="#">
    <img class="img-responsive" src="http://cs231n.github.io/assets/templates.jpg" alt="" width="100%"></a>
另外，为了便于计算，我们把偏差向量放到权重矩阵的最后一列，并在测试图像的列向量中增加一个单位末尾元素，
<a href="#">
    <img class="img-responsive" src="http://cs231n.github.io/assets/wb.jpeg" alt="" width="100%"></a>

**数据预处理：**机器学习中我们常对特征值做normalization，而再图像分类时我们常常对每个特征值减去平均值来中心化数据。上述图像在中心化后将分布在$[-127,127]$之间，然后再根据某些规则使区间变为$[-1,1]$。总之，zero mean centering是非常重要的。
{% highlight python %}
import math
print 'Hello CS231n'
{% endhighlight %}
