<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Jianfei from Mars">

    <title>Marsrock</title>

    <link rel="canonical" href="http://localhost:4000/feed.xml">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/clean-blog.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="/css/italic1.css" rel='stylesheet' type='text/css'>
    <link href="/css/italic2.css" rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!--Load ICON-->
    <link rel="icon" href="/img/flyico.ico" type="image/x-icon" />
    <link rel="shortcut icon" href="/flyico.ico" type="image/x-icon" />

    <!--Load Mathjax-->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script>
    MathJax.Hub.Config({
        config: ["MMLorHTML.js"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
        jax: ["input/TeX"],
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: false
        },
        TeX: {
            TagSide: "right",
            TagIndent: ".8em",
            MultLineWidth: "85%",
            equationNumbers: {
               autoNumber: "AMS",
            },
            unicode: {
               fonts: "STIXGeneral,'Arial Unicode MS'" 
            }
        },
        showProcessingMessages: false
    });
    </script>

    <!-- highlight the code-->
    <link rel="stylesheet" href="/css/default.css">
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>


    <!-- Autobot Icon Window -->
    <style>
    #nav { width:10%; height: auto; border: 0px; position:fixed;right:0;top:9%; z-index:100;}
    </style>
    <div id="nav">
    <img src="/img/autobot.png" width="100%" height="100%">
    </div>
    <!-- End Autobot-->
</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Marsrock</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="/">Home</a>
                </li>
                
                <li>
                    <a href="/about/">About</a>
                </li>
                
                <li>
                    <a href="/category/">Categories</a>
                </li>
                
                <li>
                    <a href="/contact/">Contact</a>
                </li>
                
                <li>
                    
                </li>
                
                <li>
                    
                </li>
                
                <li>
                    <a href="/recommend/">Recommend</a>
                </li>
                
                <li>
                    
                </li>
                
                <li>
                    
                </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Marsrock</title>
    <description>Jianfei from Mars</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 04 Apr 2018 23:33:34 +0800</pubDate>
    <lastBuildDate>Wed, 04 Apr 2018 23:33:34 +0800</lastBuildDate>
    <generator>Jekyll v3.7.3</generator>
    
      <item>
        <title>Transfer Component Analysis</title>
        <description>&lt;h2 id=&quot;引子&quot;&gt;引子&lt;/h2&gt;
&lt;p&gt;这篇文章诞生于2009年的IJCAI，也是Transfer Learning中公认的经典之作。迁移学习解决的问题是在数据不足导致Model的泛化能力不足时，应当如何通过unlabeled data提高模型的泛化能力。&lt;/p&gt;

&lt;h4 id=&quot;具体问题&quot;&gt;具体问题&lt;/h4&gt;
&lt;p&gt;TCA想要解决的问题是迁移学习中的一个有趣问题，叫做Domain Adaptation。 说有两个domain，分别是已知类标的Source Domain &lt;script type=&quot;math/tex&quot;&gt;D_S&lt;/script&gt;和未知类标的Target Domain &lt;script type=&quot;math/tex&quot;&gt;D_T&lt;/script&gt;，sample数量分别是&lt;script type=&quot;math/tex&quot;&gt;n_1&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;n_2&lt;/script&gt;。那么输入数据的边缘分布&lt;script type=&quot;math/tex&quot;&gt;P(X_S)&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;Q(X_T)&lt;/script&gt;是不同的，那么TCA的目的就是用labelled source data去预测unlabelled target data。&lt;/p&gt;

&lt;h4 id=&quot;基本假设&quot;&gt;基本假设&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P \neq Q&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y_S|X_S)=P(Y_T|X_T)&lt;/script&gt;

&lt;h2 id=&quot;正文&quot;&gt;正文&lt;/h2&gt;
&lt;p&gt;要想在两个domain的数据上使用传统机器学习方法，需要让他们的数据分布满足&lt;script type=&quot;math/tex&quot;&gt;P=Q&lt;/script&gt;。既然他们本身是不相等的，那么是否可以寻找一个nonlinear transformation &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;，使得&lt;script type=&quot;math/tex&quot;&gt;P'(\phi(X_S))=Q'(\phi(X_T))&lt;/script&gt;，映射后的分布就满足大多数分类回归方法的条件了！&lt;/p&gt;

&lt;p&gt;那么上述的假设就变成了：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y_S|\phi(X_S))=P(Y_T|\phi(X_T))&lt;/script&gt;

&lt;p&gt;而如何将两个分布拉到一起呢，这可以等同于一个优化问题，最小化两个分布的距离。用什么距离呢，这里用的是Maximum Mean Discrepancy (MMD)，这里不使用很多其他衡量方法例如KL散度，因为这些方法往往都是参数化的，很难处理。MMD是NIPS2006的一篇文章提出的，文章使用了引理“在选定函数&lt;script type=&quot;math/tex&quot;&gt;f \in C(X)&lt;/script&gt;为continuous bounded functions时，two sample test中的分布&lt;script type=&quot;math/tex&quot;&gt;p=q&lt;/script&gt;与&lt;script type=&quot;math/tex&quot;&gt;E_p(f(x))=E_q(f(x))&lt;/script&gt;是充要条件”提出了使用reproducing kernel Hilbert space (RKHS)中的核函数，并证明了他们的estimate是相当成功的。&lt;/p&gt;

&lt;p&gt;那么衡量两个新的domain在kernel下的分布距离度量可以写成：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Dist(X'_S,X'_T) = ||  \frac{1}{n_1}\sum_{i=1}^{n_1}\phi(x_{S_i})-\frac{1}{n_2}\sum_{i=1}^{n_2}\phi(x_{T_i})  ||^2_H&lt;/script&gt;

&lt;p&gt;在做这个优化问题的时候，之前的工作Maximum Mean Discrepancy Embedding (MMDE)使用了SDP半正定规划去学习一个kernel matrix，但是相当复杂。为了避免显式地计算映射&lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;，作者将其转化为一个kernel learning problem，应用kernel trick &lt;script type=&quot;math/tex&quot;&gt;k(x_i,x_j)=\phi(x_i)' \phi(x_j)&lt;/script&gt;，MMD距离可以被写成新的形式：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Dist(X'_S,X'_T) = tr(KL)&lt;/script&gt;

&lt;p&gt;其中&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
K = \begin{bmatrix} 
K_{S,S} &amp; K_{S,T} \\
K_{T,S} &amp; K_{T,T}
\end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;而L就是用来凑系数的矩阵。&lt;/p&gt;

&lt;p&gt;基本思路已经明白了，但是这时便是作者展现数学功底的时候了，只见他三下五除二，先用一个降维后的矩阵&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;使得&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;K = (KK^{-1/2}\tilde{W})(\tilde{W}^T K^{-1/2}K)=KWW^TK&lt;/script&gt;

&lt;p&gt;代入原问题，于是问题转化成了更简单的形式：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_W \quad tr(W^TW)+\mu tr(W^TKLKW)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s.t. \quad W^TKHKW=I&lt;/script&gt;

&lt;p&gt;这里我就要问了，H是啥玩意？莫名其妙就说是一个center matrix，这个条件就是TCA的第二个目的，在保持各自数据特征的前提下做domain拉近，而保持的散度特征正是&lt;script type=&quot;math/tex&quot;&gt;AHA^T&lt;/script&gt;，这里和PCA有点类似，降维后保持数据特性不变。&lt;/p&gt;

&lt;p&gt;下面解这个问题的时候，因为条件非凸，需要先做一个转化，再求它的dual problem就可以解了，解的答案简单明了，W就是求&lt;script type=&quot;math/tex&quot;&gt;(I+\mu KLK)^{-1}KHK&lt;/script&gt;的前&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt;个特征向量，而W的维度正是$(n_1+n_2) \times m$，相当于把所有数据都在分布拉近的同时，降维到了&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt;维度上，后面就可以很简单的使用各种方法进行分类和回归了。&lt;/p&gt;

&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;

&lt;p&gt;不得不说，很有趣的问题转化，思路也清楚明白，就是要让我解这个优化问题，那真是老费劲了。科科。&lt;/p&gt;

</description>
        <pubDate>Wed, 04 Apr 2018 21:53:00 +0800</pubDate>
        <link>http://localhost:4000/transfer%20learning/2018/04/04/Transfer-Component-Analysis/</link>
        <guid isPermaLink="true">http://localhost:4000/transfer%20learning/2018/04/04/Transfer-Component-Analysis/</guid>
        
        <category>TCA</category>
        
        
        <category>Transfer Learning</category>
        
      </item>
    
      <item>
        <title>A Lua Primer plus Torch</title>
        <description>&lt;h2 id=&quot;lua&quot;&gt;Lua&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Lua是一个高性能的轻量级的脚本语言。&lt;/li&gt;
  &lt;li&gt;广泛应用于游戏脚本（暴雪WOW），nginx，wireshark的脚本。&lt;/li&gt;
  &lt;li&gt;Lua由标准C编写而成，和C/C++语言有非常好的交互。&lt;/li&gt;
  &lt;li&gt;Lua没有提供强大的库，不适合作为开发独立应用程序的语言。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;lua的安装&quot;&gt;lua的安装&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-linux&quot; data-lang=&quot;linux&quot;&gt;curl -R -O http://www.lua.org/ftp/lua-5.3.0.tar.gz
tar zxf lua-5.3.0.tar.gz
cd lua-5.3.0
make macosx test
make install&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Lua也有交互式编程模式，可以通过命令lua直接启动，也可以写好hello.lua文件然后执行。先来学习一波基本语法和特性！&lt;/p&gt;

&lt;h4 id=&quot;lua-基本语法&quot;&gt;Lua 基本语法&lt;/h4&gt;
&lt;h5 id=&quot;注释&quot;&gt;[注释]&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;c1&quot;&gt;-- 两个减号为注释&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 书写时通过指定lua解释器来运行脚本&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;local&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lua&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;标示符&quot;&gt;[标示符]&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;c1&quot;&gt;-- 用于定义一个变量，函数获取其他用户定义的项。标示符以一个字母 A 到 Z 或 a 到 z 或下划线 _ 开头后加上0个或多个字母，下划线，数字（0到9）。最好不要使用下划线加大写字母的标示符，因为Lua的保留字也是这样的。&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 变量默认为全局变量&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 删除变量，只需赋值nil&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;nil&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 局部变量&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;数据类型&quot;&gt;[数据类型]&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;c1&quot;&gt;--nil: 无效值&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--boolean: false/true&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--number: 只有double&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--string: 双引号/单引号&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--function: 比如print&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--userdata: 存储在变量中的C数据结构&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--thread: 表示执行的独立线路&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--table: 关联数组&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;赋值&quot;&gt;[赋值]&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;c1&quot;&gt;--同时对多个赋值&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;--对table索引&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;site&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;site&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;key&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;marsrock.net&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;循环&quot;&gt;[循环]&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;c1&quot;&gt;--循环会在开始前一次性求值，之后不在求值&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;函数&quot;&gt;[函数]&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;cm&quot;&gt;--[[ 函数返回两个值的最大值 --]]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

   &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 调用函数&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;两值比较最大值为 &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;两值比较最大值为 &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;字符串&quot;&gt;[字符串]&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;c1&quot;&gt;--string functions&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;lua&quot;&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;string.upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;string.lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;string.gsub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mainString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;findString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replaceString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;string.find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Hello Lua user&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Lua&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;string.reverse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Lua&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;string.len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;abc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;abc&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;def&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;--连接字符串&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;数组&quot;&gt;[数组]&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Lua&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Tutorial&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
   &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;面向对象&quot;&gt;[面向对象]&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;c1&quot;&gt;-- Meta class&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;area&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- 基础类方法 new&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;side&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;setmetatable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;side&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;side&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;area&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;side&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;side&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-lua&quot; data-lang=&quot;lua&quot;&gt;&lt;span class=&quot;c1&quot;&gt;-- 基础类方法 printArea&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;printArea&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;面积为 &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;area&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- 创建对象&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;myshape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;nil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;myshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;printArea&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;torch&quot;&gt;Torch&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Torch 是一个lua编写的十分老牌、对多维矩阵数据进行操作的张量（tensor ）库。&lt;/li&gt;
  &lt;li&gt;Facebook的AI团队发布了Pytorch，针对GPU加速的DNN编程。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;安装&quot;&gt;安装&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;&lt;span class=&quot;c&quot;&gt;# in a terminal, run the commands WITHOUT sudo&lt;/span&gt;
git clone https://github.com/torch/distro.git ~/torch &lt;span class=&quot;nt&quot;&gt;--recursive&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; ~/torch&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; bash install-deps&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
./install.sh&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;将PATH生效后，就可以正常通过th启动Torch7了，也可以通过luarocks安装包。
Lua可以通过luarocks安装包。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;luarocks &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;image
luarocks list&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Fri, 13 Oct 2017 19:18:00 +0800</pubDate>
        <link>http://localhost:4000/programming/2017/10/13/A-Lua-Primer-plus-Torch/</link>
        <guid isPermaLink="true">http://localhost:4000/programming/2017/10/13/A-Lua-Primer-plus-Torch/</guid>
        
        <category>Code</category>
        
        <category>Lua</category>
        
        
        <category>Programming</category>
        
      </item>
    
      <item>
        <title>A Scala Primer</title>
        <description>&lt;h3 id=&quot;scala&quot;&gt;Scala&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Scala运行于Java平台（Java虚拟机），并兼容现有的Java程序。&lt;/li&gt;
  &lt;li&gt;洛桑联邦理工学院的Martin Odersky于2001年基于Funnel的工作开始设计Scala。&lt;/li&gt;
  &lt;li&gt;Twitter, Coursera的后台服务器语言&lt;/li&gt;
  &lt;li&gt;特性：面向对象、函数式编程、静态类型、扩展性、并发性。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;基本语法&quot;&gt;基本语法&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;c1&quot;&gt;//Run the interpreter 
//sbt console 
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//值，不变量 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;two&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//变量，绑定结果和名称 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;jianfei&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//函数 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;addOne&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//不带参函数，可以省略括号 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;three&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//匿名函数 
&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//可以传递匿名函数，同时定义了它的使用名称
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;addOne&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//用大括号格式化代码 
&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hello world&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//部分应用 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;add2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adder&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;add2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//会得到5，下划线表示了部分应用了一个函数 
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//柯里化函数 
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//允许之应用一部分参数 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timesTwo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//可变长度参数，可以传多个同类型参数 
//这里对args的每一个arg进行了大写操作 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;capitalizeAll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;capitalize&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//类 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Calculator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;brand&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Hp&quot;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//构造函数 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Calculator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;brand&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;brand&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;TI&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;brand&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;HP&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;black&quot;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;white&quot;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//函数和方法在很大程度上是可以互换的。 
//由于函数和方法是如此的相似，你可能都不知道你调用的东西是一个函数还是一个方法。
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt;  &lt;span class=&quot;nc&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minc&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finc&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//继承 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ScientificCalculator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;brand&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Calculator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;brand&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//抽象类 
//你可以定义一个抽象类，它定义了一些方法但没有实现它们。 
//取而代之是由扩展抽象类的子类定义这些方法。你不能创建抽象类的实例。 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;abstract&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getArea&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//重载
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Circle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getArea&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Circle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//特质(Traits) 
//特质是一些字段和行为的集合，可以扩展或混入（mixin）你的类中。 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Car&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;brand&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Shiny&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shineRefraction&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BMW&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Car&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;brand&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;BMW&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//通过with，可以同时扩展多个特质 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BMW&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Car&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Shiny&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;brand&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;BMW&quot;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;shineRefraction&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//类型 
//其实函数也可以是泛型的，来适用于所有类型。 
//当这种情况发生时，你会看到用方括号语法引入的类型参数。 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]{&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//方法也可以 
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Wed, 12 Oct 2016 21:36:00 +0800</pubDate>
        <link>http://localhost:4000/programming/2016/10/12/A-Scala-Primer/</link>
        <guid isPermaLink="true">http://localhost:4000/programming/2016/10/12/A-Scala-Primer/</guid>
        
        <category>Code</category>
        
        <category>Scala</category>
        
        
        <category>Programming</category>
        
      </item>
    
      <item>
        <title>CS231n: Neural Nets</title>
        <description>&lt;h2 id=&quot;神经网络-neural-networks&quot;&gt;神经网络 Neural Networks&lt;/h2&gt;

&lt;p&gt;神经网络算法的计算公式是&lt;script type=&quot;math/tex&quot;&gt;s=W_2 max(0, W_1 x)&lt;/script&gt;。&lt;script type=&quot;math/tex&quot;&gt;W_1&lt;/script&gt;可以将图像转化为一个相比分类个数来说高维一些的特征过渡向量。比如对于CIFAR-10中，该矩阵大小为&lt;script type=&quot;math/tex&quot;&gt;[100\times 3072]&lt;/script&gt;。函数&lt;script type=&quot;math/tex&quot;&gt;max(0, ~)&lt;/script&gt;为非线性，会作用到每个元素，这个非线性函数可以更换。第二个矩阵&lt;script type=&quot;math/tex&quot;&gt;W_2&lt;/script&gt;则是&lt;script type=&quot;math/tex&quot;&gt;[10\times100]%&lt;/script&gt;，可以得到最终的10个分类评分。两个参数矩阵可以通过随机梯度下降来学习（梯度通过反向传播的链式法则求导计算），而神经网络的关键改变在于非线性函数的引入。最终，一个三层的神经网络可以写成&lt;script type=&quot;math/tex&quot;&gt;s=W_3 max(0,W_2 max(0,W_1 x))&lt;/script&gt;，其中包括三个权重矩阵需要学习，而中间隐层的尺寸是网络而超参数。&lt;/p&gt;

&lt;h3 id=&quot;单个神经元&quot;&gt;单个神经元&lt;/h3&gt;

&lt;p&gt;生物学中的神经元通过树突获得输入信号，然后沿着他唯一的轴突产生输出信号。从仿生的方向考虑，单个神经元的计算模式为基于其他神经元输入的突触强度(&lt;script type=&quot;math/tex&quot;&gt;w_i&lt;/script&gt;)，与其他神经元的树突进行乘法交互。突触的强度可以控制一个神经元对于另一个神经元的影响强度，使其兴奋或者抑制。各输入信号在胞体中进行叠加，若高于某阈值则会激活神经元，向轴突输出一个峰值信号。神经元的激活率建模为激活函数，它常常选择使用sigmoid函数，它将输入信号值压缩到0-1之间。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
&lt;img class=&quot;img-responsive&quot; src=&quot;/img/post-backprop.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 04 Oct 2016 10:36:00 +0800</pubDate>
        <link>http://localhost:4000/course/2016/10/04/CS231n-Neural-Nets/</link>
        <guid isPermaLink="true">http://localhost:4000/course/2016/10/04/CS231n-Neural-Nets/</guid>
        
        <category>CS231n</category>
        
        
        <category>Course</category>
        
      </item>
    
      <item>
        <title>CS231n: Back Propagation</title>
        <description>&lt;h2 id=&quot;反向传播&quot;&gt;反向传播&lt;/h2&gt;

&lt;p&gt;反向传播是用来计算给定函数&lt;script type=&quot;math/tex&quot;&gt;f(x)&lt;/script&gt;关于&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;的梯度&lt;script type=&quot;math/tex&quot;&gt;\bigtriangledown f(x)&lt;/script&gt;，根据梯度可以更快地进行参数更新。&lt;/p&gt;

&lt;h2 id=&quot;简单表达式&quot;&gt;简单表达式&lt;/h2&gt;

&lt;p&gt;函数变量在某个点周围的极小区域内变化，导数和偏导数就是沿着某个方向的变化率，而梯度则是偏导数的向量：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{df(x)}{dx}=lim_{h \to 0}\frac{f(x+h)-f(x)}{h}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bigtriangledown f(x, y)=[\frac{\partial f}{x}, \frac{\partial f}{y}]&lt;/script&gt;

&lt;h2 id=&quot;链式法则&quot;&gt;链式法则&lt;/h2&gt;
&lt;p&gt;链式法则就是我们高数里学过的，复合函数求导时，导数等于各个复合函数梯度表达式（导数）的乘积。在实际代码实现时，只是单纯将两个梯度数值相乘：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# 设置输入值&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 进行前向传播&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# q becomes 3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# f becomes -12&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 进行反向传播:&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 首先回传到 f = q * z&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dfdz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# df/dz = q, 所以关于z的梯度是3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dfdq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# df/dq = z, 所以关于q的梯度是-4&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 现在回传到q = x + y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dfdx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dfdq&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# dq/dx = 1. 这里的乘法是因为链式法则&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dfdy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dfdq&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# dq/dy = 1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;图中展示了计算的过程，前向传播将输入值用于计算输出，反向传播从尾部开始，利用链式法则递归计算梯度。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;/img/post-backprop.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;反向传播的意义&quot;&gt;反向传播的意义&lt;/h3&gt;
&lt;p&gt;反向传播可以看做门单元之间通过梯度信号进行通信，让它们的输入沿着梯度方向变化，局部计算后可以提升整个网络的输出值。实际上，无论是乘法、加法还是MAX都可以看做是门。初此之外还有以下四种门：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x)=\frac{1}{x} \to \frac{df}{dx}=-\frac{1}{x^2}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_c(x)=c+x \to \frac{df}{dx}=1&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x)=e^x \to \frac{df}{dx}=e^x&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_a(x)=ax \to \frac{df}{dx}=a&lt;/script&gt;

&lt;p&gt;其中包括将输入值平移和实数倍放大的函数。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sigmoid例子
一个函数可以看成多个门的结合，下面的表达式描述了一个含输入&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;和权重&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;的二维神经元，该神经元使用了sigmoid激活函数。这个函数可以如下计算：
&lt;a href=&quot;#&quot;&gt;
  &lt;img class=&quot;img-responsive&quot; src=&quot;/img/post-backprop2.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;
对于sigmoid函数，其求导使可以进行简化的，因为我们发现：
&lt;script type=&quot;math/tex&quot;&gt;\sigma(x)=\frac{1}{1+e^{-x}}&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;\frac{d\sigma(x)}{dx}=(1-\sigma(x))\sigma(x)&lt;/script&gt;
而在具体实现中，可以使用分段的反向传播，可以让局部梯度计算简洁，代码量小，效率高。&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 假设一些随机数据和权重&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 前向传播&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# sigmoid函数&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 对神经元反向传播&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ddot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 点积变量的梯度, 使用sigmoid函数求导&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 回传到x&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 回传到w&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;分段计算
输入的函数如下：
&lt;script type=&quot;math/tex&quot;&gt;f(x,y)=\frac{x+\sigma(y)}{\sigma(x)+(x+y)^2}&lt;/script&gt;
这个函数如果进行微分运算，将会得到巨大复杂的展开式。其实我们根本不需要明确的函数来计算梯度，只需要通过反向传播就好了。首先构建前向传播的代码：&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 例子数值&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 前向传播&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sigy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 分子中的sigmoi          #(1)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigy&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 分子                                    #(2)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sigx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 分母中的sigmoid         #(3)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xpy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;                                              &lt;span class=&quot;c&quot;&gt;#(4)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;xpysqr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xpy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;                                          &lt;span class=&quot;c&quot;&gt;#(5)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;den&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xpysqr&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 分母                                #(6)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;invden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;den&lt;/span&gt;                                       &lt;span class=&quot;c&quot;&gt;#(7)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;invden&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 搞定！                                 #(8)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;然后这些中间变量都是比较简单的表达式，它们计算梯度的方法都很简单。所以我们只需要将这些变量的值进行回传就可以计算对应的梯度了：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# 回传 f = num * invden&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dnum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;invden&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 分子的梯度                                         #(8)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dinvden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;                                                     &lt;span class=&quot;c&quot;&gt;#(8)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 回传 invden = 1.0 / den &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;den&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dinvden&lt;/span&gt;                                &lt;span class=&quot;c&quot;&gt;#(7)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 回传 den = sigx + xpysqr&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dsigx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dden&lt;/span&gt;                                                &lt;span class=&quot;c&quot;&gt;#(6)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dxpysqr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dden&lt;/span&gt;                                              &lt;span class=&quot;c&quot;&gt;#(6)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 回传 xpysqr = xpy**2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dxpy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dxpysqr&lt;/span&gt;                                        &lt;span class=&quot;c&quot;&gt;#(5)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 回传 xpy = x + y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dxpy&lt;/span&gt;                                                   &lt;span class=&quot;c&quot;&gt;#(4)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dxpy&lt;/span&gt;                                                   &lt;span class=&quot;c&quot;&gt;#(4)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 回传 sigx = 1.0 / (1 + math.exp(-x))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsigx&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# Notice += !! See notes below  #(3)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 回传 num = x + sigy&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dnum&lt;/span&gt;                                                  &lt;span class=&quot;c&quot;&gt;#(2)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dsigy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dnum&lt;/span&gt;                                                &lt;span class=&quot;c&quot;&gt;#(2)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 回传 sigy = 1.0 / (1 + math.exp(-y))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dsigy&lt;/span&gt;                                 &lt;span class=&quot;c&quot;&gt;#(1)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 完成! 嗷~~&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;中间有大量的中间变量需要缓存，在不同分支的梯度计算后，如果同一变量在前向传播中出现多次，就要通过微积分中的多元链式法则进行累加。&lt;/p&gt;

&lt;h3 id=&quot;回传流中的模式&quot;&gt;回传流中的模式&lt;/h3&gt;
&lt;p&gt;观察一个包括加法乘法流的例子：
&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;/img/post-backprop3.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以看出，每种门单元有着不同的回传机制：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;加法门：把输出的梯度相等地分发给它所有的输入，这一行为与输入值在前向传播时的值无关。这是因为加法操作的局部梯度都是简单的+1，所以所有输入的梯度实际上就等于输出的梯度，因为乘以1.0保持不变。&lt;/li&gt;
  &lt;li&gt;max门：对梯度做路由。取最大值门将梯度转给其中一个输入，这个输入是在前向传播中值最大的那个输入。这是因为在取最大值门中，最高值的局部梯度是1.0，其余的是0。（选择器）&lt;/li&gt;
  &lt;li&gt;乘法门：它的局部梯度就是输入值，但是是相互交换之后的，然后根据链式法则乘以输出值的梯度。但是如果一个输入非常大，一个非常小，那么交换后获得的梯度将会跟输入数据的大小密切相关。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;矩阵操作&quot;&gt;矩阵操作&lt;/h3&gt;
&lt;p&gt;当真正进行计算时，大多是矩阵和向量操作。矩阵相乘时有很多好的操作习惯，比如矩阵转置，比如维度分析：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# 前向传播&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 假设我们得到了D的梯度&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 和D一样的尺寸&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#.T就是对矩阵进行转置&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dX&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;通过反向传播，程序可以通过简单地编写实现高效的参数计算。下节课我将会学习神经网络的基本概念，而其其训练的数学理论基本就来源于最优化与反向传播了。&lt;/p&gt;
</description>
        <pubDate>Mon, 03 Oct 2016 15:56:00 +0800</pubDate>
        <link>http://localhost:4000/course/2016/10/03/CS231n-Back-Propagation/</link>
        <guid isPermaLink="true">http://localhost:4000/course/2016/10/03/CS231n-Back-Propagation/</guid>
        
        <category>CS231n</category>
        
        
        <category>Course</category>
        
      </item>
    
      <item>
        <title>CS231n: Optimization</title>
        <description>&lt;h2 id=&quot;最优化-optimization&quot;&gt;最优化 Optimization&lt;/h2&gt;

&lt;p&gt;最优化就是通过计算权重&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;来最小化损失函数。如果损失函数是SVM损失，那么这个凸函数是可以用凸优化的方法进行的。但是当损失函数扩展成为神经网络时，那么目标函数就不是凸函数了，而且损失函数中存在不可导点(kinks)，使得这些点不可微，在这些点也没有梯度的定义。但是次梯度(subgradient)依然可以使用。&lt;/p&gt;

&lt;p&gt;我们从最基本的方案开始逐步过渡到梯度的方法。&lt;/p&gt;

&lt;h3 id=&quot;随机搜索&quot;&gt;&lt;strong&gt;随机搜索&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;大量随机生成权重矩阵，然后比较它们的损失值，取最小的权重作为我们要找的权重去跑测试集。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# 假设X_train的每一列都是一个数据样本（比如3073 x 50000）&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 假设Y_train是数据样本的类别标签（比如一个长50000的一维数组）&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 假设函数L对损失函数进行评价&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;bestloss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;inf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# Python assigns the highest possible float value&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;xrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3073&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# generate random parameters&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# get the loss over the entire training set&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bestloss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# keep track of the best solution&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bestloss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bestW&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'in attempt &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d the loss was &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f, best &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bestloss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 测试函数&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 假设X_test尺寸是[3073 x 10000], Y_test尺寸是[10000 x 1]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Wbest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Xte_cols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 10 x 10000, the class scores for all test examples&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 找到在每列中评分值最大的索引（即预测的分类）&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Yte_predict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 以及计算准确率&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Yte_predict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Yte&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 返回 0.1555&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;当随机猜测时，正确概率是10%，这里用多次筛选得到随机矩阵提升了一点。如果我们能够设计一个迭代算法，使得每次迭代后的损失值都减少一点，那么就能找到更好的&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;。&lt;/p&gt;

&lt;h3 id=&quot;随机本地搜索&quot;&gt;&lt;strong&gt;随机本地搜索&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;设计一个迭代算法，每一次都随机尝试几个方向，如果方向是向下（能让损失值小一点），那就向该方向走一步。依然从随机的&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;开始，每次给予一个随机扰动&lt;script type=&quot;math/tex&quot;&gt;\delta W&lt;/script&gt;，如果扰动后损失值更小了，就更新权重矩阵。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3073&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 生成随机初始W&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bestloss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;inf&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;xrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Wtry&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3073&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Xtr_cols&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Ytr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Wtry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bestloss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Wtry&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bestloss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'iter &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d loss is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bestloss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;用同样的方法，相比上述方法准确率更高（20%），但是因为迭代过程是随机的，所以训练时间和效果都不稳定。&lt;/p&gt;

&lt;h3 id=&quot;跟随梯度&quot;&gt;&lt;strong&gt;跟随梯度&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;这里的迭代算法保证了每次都是走向局部最优的低处，这个方向就是损失函数的梯度(gradient)。&lt;strong&gt;梯度是各个维度的斜率组成的向量(导数derivatives)&lt;/strong&gt;。当函数有多个参数时，梯度是每个维度上偏导数所形成的向量。&lt;/p&gt;

&lt;h2 id=&quot;梯度计算&quot;&gt;梯度计算&lt;/h2&gt;

&lt;p&gt;计算梯度的方法有两种：数值梯度法（近似），分析梯度法（精确，需要微分）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;有限差值法近似求梯度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;用梯度公式&lt;script type=&quot;math/tex&quot;&gt;\frac{f(x+h)-f(x)}{h}&lt;/script&gt;在所有维度上进行计算，得到的grad中包括了在每个维度上的偏导数。h的取值越小越好，实际中使用中心差值公式(centered difference formula，对称差分中一次项误差相消)会更好，公式为&lt;script type=&quot;math/tex&quot;&gt;\frac{[f(x+h)-f(x-h)]}{2h}&lt;/script&gt;。以下函数是根据输入函数与向量计算函数梯度的函数：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;eval_numerical_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;  
  一个f在x处的数值梯度法的简单实现
  - f是只有一个参数的函数
  - x是计算梯度的点
  &quot;&quot;&quot;&lt;/span&gt; 

  &lt;span class=&quot;n&quot;&gt;fx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 在原点计算函数值&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.00001&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# 对x中所有的索引进行迭代&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nditer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'multi_index'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op_flags&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'readwrite'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finished&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 计算x+h处的函数值&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multi_index&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;old_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;old_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 增加h&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fxh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 计算f(x + h)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;old_value&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 存到前一个值中 (非常重要)&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# 计算偏导数&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fxh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 坡度&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iternext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 到下个维度&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 要使用上面的代码我们需要一个只有一个参数的函数&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# (在这里参数就是权重)所以也包含了X_train和Y_train&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;CIFAR10_loss_fun&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3073&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 随机权重向量&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eval_numerical_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CIFAR10_loss_fun&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 得到梯度&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 用得到的梯度更新权重&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss_original&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CIFAR10_loss_fun&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 初始损失值&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'original loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_original&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# 查看不同步长的效果&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size_log&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size_log&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;W_new&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 权重空间中的新位置&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;loss_new&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CIFAR10_loss_fun&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'for step size &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f new loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;通过这个函数可以计算任何函数在任意点上的梯度，并用于更新权重。这里是向着梯度的负方向进行更新，因为我们希望损失函数值是降低的。在这个计算过程中，学习步长是关键的超参数（学习率），过大的步长会导致更高的损失值。&lt;/p&gt;

&lt;p&gt;使用数值近似的方法每一步要计算N维权值矩阵的每一个梯度，当神经网络中参数众多时，这个方法将不再适合。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;微分分析法&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;用微分的方法得到损失函数的梯度公式，不好的地方在于容易出错。所以在实际应用时，会将分析梯度法与数值梯度法结果比较，来检查微分分析的正确性，这个步骤叫做&lt;strong&gt;梯度检查&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;这里将SVM损失函数进行微分：&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;L_i=\sum_{j \neq y_i}[max(0,w_j^T x_i-w_{y_i}^T x_i+\Delta)]&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;\bigtriangledown_{w_{y_i}} L_i=-(\sum_{j \neq y_i}\mathbb{I}(w_j^T x_i-w_{y_i}^T x_i+\Delta&gt;0))x_i&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;其中的&lt;script type=&quot;math/tex&quot;&gt;\mathbb{I}&lt;/script&gt;是一个示性函数，若括号中条件为真则函数值为1，否则为0。这里的微分公式非常简单，不满足条件的分类乘以&lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt;就是梯度了。这里的梯度对应正确分类的权值矩阵行向量梯度，其他行的梯度为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bigtriangledown_{w_{y_i}} L_i=\mathbb{I}(w_j^T x_i-w_{y_i}^T x_i+\Delta&gt;0)x_i&lt;/script&gt;

&lt;h3 id=&quot;梯度下降&quot;&gt;梯度下降&lt;/h3&gt;

&lt;p&gt;得到损失函数的梯度后就可以进行梯度下降的过程。普通的梯度下降法只适用于小数据量，在大数据量下，计算整个数据集来获取一个参数的代价过高，常用方法是计算训练集中的小批量(batches)数据。因为训练集中的数据大多相关，通过小批量数据梯度计算可以实现快速收敛，以此进行更频繁地更新。&lt;/p&gt;

&lt;p&gt;当每个批量中只有一个数据样本时，这种策略被称为随机梯度下降(Stochastic Gradient Descent, SGD)。一般来说，小批量数据的大小一般使用2的指数，因为它由存储器限制，输入是2的倍数时运算会大大加快。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# 普通的梯度下降&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;weights_grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;evaluate_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_fun&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights_grad&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 进行梯度更新&lt;/span&gt;


&lt;span class=&quot;c&quot;&gt;# 普通的小批量数据梯度下降&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;data_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_training_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 256个数据&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;weights_grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;evaluate_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_fun&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights_grad&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 参数更新&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;最优化是为了解决损失函数最小时权重矩阵如何得到的问题，也就是求参的问题。当损失函数为凸函数可以使用凸优化，而当不可微点多或非凸函数时，则要使用梯度下降的方法求局部最优，有时近似法也要用来进行梯度检查。
&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://cs231n.github.io/assets/dataflow.jpeg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;后面我将继续学习&lt;strong&gt;反向传播(backpropagation)机制&lt;/strong&gt;，它使用链式法则来高效计算梯度，能够对包含CNN在内的大多数神经网络的损失函数进行最优化。&lt;/p&gt;

</description>
        <pubDate>Wed, 28 Sep 2016 10:36:00 +0800</pubDate>
        <link>http://localhost:4000/course/2016/09/28/CS231n-Optimization/</link>
        <guid isPermaLink="true">http://localhost:4000/course/2016/09/28/CS231n-Optimization/</guid>
        
        <category>CS231n</category>
        
        
        <category>Course</category>
        
      </item>
    
      <item>
        <title>CS231n: Linear Classification</title>
        <description>&lt;h2 id=&quot;cs231n-introduction&quot;&gt;CS231n Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://cs231n.stanford.edu/&quot;&gt;Stanford CS231n-Convolutional Neural Networks for Visual Recognition(Winter 2016)&lt;/a&gt;是一门讲述CNN在图像识别和分类中应用的课程，由Prof. Feifei Li授课。它包括两个模块，分别是Neural Networks和Convolutional Neural Networks，课程可用资源为&lt;a href=&quot;http://cs231n.github.io/&quot;&gt;Course Notes&lt;/a&gt;与&lt;a href=&quot;https://zhuanlan.zhihu.com/intelligentunit&quot;&gt;知乎翻译版&lt;/a&gt;。另外在Youtube中有完整版的&lt;a href=&quot;https://www.youtube.com/playlist?list=PLLvH2FwAQhnpj1WEB-jHmPuUeQ8mX-XXG&quot;&gt;Lecture Video&lt;/a&gt;。使用的数据集来自多伦多大学的&lt;a href=&quot;https://www.cs.toronto.edu/~kriz/cifar.html&quot;&gt;Cifar-10&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;选择这门MOOC来自学，也是想在做其他领域的同时不抛弃原本做过的计算机视觉领域，并将机器学习与神经网络的知识融会贯通，说不定会在自己的领域有新的想法。&lt;/p&gt;

&lt;p&gt;前几章铺垫的部分讲述了&lt;strong&gt;Python与numpy库&lt;/strong&gt;的基本用法，并简单阐述了&lt;strong&gt;图像分类&lt;/strong&gt;这一概念的目标与简单实现方法（KNN）。笔记我将直接从线性分类器开始写起。&lt;/p&gt;

&lt;h3 id=&quot;线性分类&quot;&gt;线性分类&lt;/h3&gt;
&lt;p&gt;图像分类是从已有的固定标签中选择一个合适的标签给一张新的图像。k-Nearest Neighbor分类器通过比较新图像&lt;script type=&quot;math/tex&quot;&gt;I_{test}&lt;/script&gt;与所有训练集&lt;script type=&quot;math/tex&quot;&gt;{I_{train}}&lt;/script&gt;的距离来判断它的标签。但是k-NN需要将所有的训练数据存储用于比较，存储与计算的复杂度高。&lt;/p&gt;

&lt;p&gt;我们需要实现一种新的方法来解决图像分类问题。它包括两个部分：一个是&lt;strong&gt;评分函数(score function)&lt;/strong&gt;，是从原始图像到类标的映射；另一个是&lt;strong&gt;损失函数(loss function)&lt;/strong&gt;，用来量化预测结果与真实结果的一致性。于是该方法可以被转化为一个&lt;strong&gt;最优化问题&lt;/strong&gt;，通过更新评分函数的参数来最小化损失函数的结果。&lt;/p&gt;

&lt;h3 id=&quot;评分函数&quot;&gt;评分函数&lt;/h3&gt;
&lt;p&gt;评分函数将图像的像素值映射到各个类别的得分，而得分的高低代表了属于该类别的可能性高低。我们假设一个包含很多图像的训练集&lt;script type=&quot;math/tex&quot;&gt;x_i \in R^D&lt;/script&gt;，对应一个分类标签&lt;script type=&quot;math/tex&quot;&gt;y_i&lt;/script&gt;且&lt;script type=&quot;math/tex&quot;&gt;y_i \in 1, ..., K&lt;/script&gt;。这里我们有个&lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt;训练样本，图像维度为&lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt;，有&lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt;种分类标签。在CIFAR-10中，&lt;script type=&quot;math/tex&quot;&gt;N=50000&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;D=32\times32\times3&lt;/script&gt;，&lt;script type=&quot;math/tex&quot;&gt;K=10&lt;/script&gt;，定义评分函数&lt;script type=&quot;math/tex&quot;&gt;f: R^D\\to R^K&lt;/script&gt;。&lt;/p&gt;

&lt;p&gt;最简单的概率函数就是线性映射，也就是线性分类器的评分函数：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x_i,W,b)=Wx_i+b&lt;/script&gt;

&lt;p&gt;其中&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;被称为权重，&lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;被称为偏差向量。输入图像&lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt;被拉长为一个长度为D的列向量。&lt;/p&gt;

&lt;p&gt;这样训练后得到的权值矩阵就代表了训练数据给出的分类信息，而不用再保留大量的训练数据。而计算复杂度只是一个矩阵乘法和加法就够了。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://cs231n.github.io/assets/imagemap.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;
首先将图像像素拉伸为一个列向量，与W进行矩阵乘，然后得到各个分类的分值。这个过程实际上是在高维空间当中的线性二值分类。线性分类器中的权重矩阵每一行对应着一个分类的模板，而图像不同分类的得分是通过计算图像与模板的内积得到的。模板是通过训练集训练得到的，而内积衡量了距离（相似度）。
&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://cs231n.github.io/assets/templates.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;
另外，为了便于计算，我们把偏差向量放到权重矩阵的最后一列，并在测试图像的列向量中增加一个单位末尾元素，
&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://cs231n.github.io/assets/wb.jpeg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;数据预处理：&lt;/strong&gt;机器学习中我们常对特征值做normalization，而再图像分类时我们常常对每个特征值减去平均值来中心化数据。上述图像在中心化后将分布在&lt;script type=&quot;math/tex&quot;&gt;[-127,127]&lt;/script&gt;之间，然后再根据某些规则使区间变为&lt;script type=&quot;math/tex&quot;&gt;[-1,1]&lt;/script&gt;。总之，zero mean centering是非常重要的。&lt;/p&gt;

&lt;h3 id=&quot;损失函数&quot;&gt;损失函数&lt;/h3&gt;
&lt;p&gt;损失函数(Loss function)也被称为代价(cost)函数和目标(objective)函数，用来衡量计算的得分(score)与图像真实标签的差异。损失越大，差异越大，评分函数越差。损失函数有很多种，这里学习的是多类支持向量机损失(Multiclass Support Vector Machine Loss)。&lt;/p&gt;

&lt;p&gt;SVM损失是让正确分类始终比错误分类的得分高出一个阈值&lt;script type=&quot;math/tex&quot;&gt;\Delta&lt;/script&gt;。给出第&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;个数据包括&lt;script type=&quot;math/tex&quot;&gt;x_i, y_i&lt;/script&gt;，评分函数得到第&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;个类别的评分&lt;script type=&quot;math/tex&quot;&gt;s_j=f(x_i,W)_j&lt;/script&gt;。那么这个数据的损失函数就是：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_i=\sum_{j\neq y_i}max(0,s_j-s_{y_i}+\Delta)&lt;/script&gt;

&lt;p&gt;就是得分s中每个分量，减去正确分类的分量再加上阈值。这就相当于统计了第i个数据下，所有其他得分与正确得分的安全距离，如果大于&lt;script type=&quot;math/tex&quot;&gt;\Delta&lt;/script&gt;我们认为安全距离是0，如果距离小于阈值我们就会得到一个正数，就会增大损失函数。在线性评分函数下，损失函数可以展开为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_i=\sum_{j\neq y_i}max(0,w_j^T x_i-w_{y_i}^T x_i+\Delta)&lt;/script&gt;

&lt;p&gt;而这里的&lt;script type=&quot;math/tex&quot;&gt;max(0,-)&lt;/script&gt;是折叶损失(hinge loss)，将小于阈值的部分归为0。还有一种叫做L2-SVM，公式为&lt;script type=&quot;math/tex&quot;&gt;max(0,-)^2&lt;/script&gt;用平方惩罚边界值，增大了惩罚。总的来说，损失函数形象地将不满意程度量化，使得正确类标得分与其他得分之间有一个满意的区间。
&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://cs231n.github.io/assets/margin.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;通过损失函数优化的评分函数&lt;script type=&quot;math/tex&quot;&gt;W&lt;/script&gt;此时并不唯一，比如&lt;script type=&quot;math/tex&quot;&gt;\lambda W&lt;/script&gt;的效果与其一模一样，都可以正确分类。我们通过引进一个正则化惩罚(regularization penalty &lt;script type=&quot;math/tex&quot;&gt;R(W)&lt;/script&gt;)来抑制大数值的权重，下面是一个常用的L2范式正则化惩罚，它将所有的元素的平方和作为惩罚：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R(W)=\sum_k \sum_l W_{k,l}^2&lt;/script&gt;

&lt;p&gt;最终的SVM损失函数由数据损失&lt;script type=&quot;math/tex&quot;&gt;L_i&lt;/script&gt;和正则化损失组成：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L=\frac{1}{N}\sum_i L_i + \lambda R(W)&lt;/script&gt;

&lt;p&gt;其中N是训练集数据量，&lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;需要通过交叉验证来获取。通过引入正则化损失，SVM就有了最大边界(max margin)。&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;正则化为了解决目标函数会发生过拟合的问题，所以对模型的参数做一定的限制，使得模型偏好简单的参数。L1正则化使得优化后的参数向量比较稀疏，而L2正则化使得正则化项处处可导。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;通过正则化，权重向量会变得更加分散，没有过大的权重值。也就是鼓励分类器更多的利用所有维度（像素）的特征，而不是依赖于少数几个元素进行分类（从而发生过拟合）。这称为提升了权重矩阵的泛化能力。偏差不需要进行正则化。&lt;/p&gt;

&lt;p&gt;在实践使用时：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;最大边界通常被设置成&lt;script type=&quot;math/tex&quot;&gt;\Delta=1.0&lt;/script&gt;，因为它与另一个超参数&lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;同时控制了数据损失与正则化损失的权衡比例。这就决定了实际边界的大小。所以我们只需要确定一个来训练另一个正则化强度参数就可以了。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;损失函数的最优化不限制初始条件。虽然损失函数大多不可微，但是通常可以使用次梯度(subgradient)求解。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这里的SVM是多种SVM公式中的一种，还有常见的是One-Vs-All(OVA) SVM，它对每个类与其他类训练独立的二元分类器。还有一种更少见的All-Vs-All(AVA) SVM。有一种有趣的SVM称为Structured SVM，它将正确分类的分类分值和非正确分类中的最高分值的边界最大化。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下是一个数据损失的简单实现。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;L_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  unvectorized version. Compute the multiclass svm loss for a single example (x,y)
  - x is a column vector representing an image (e.g. 3073 x 1 in CIFAR-10)
    with an appended bias dimension in the 3073-rd position (i.e. bias trick)
  - y is an integer giving index of correct class (e.g. between 0 and 9 in CIFAR-10)
  - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10)
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# see notes about delta later in this section&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# scores becomes of size 10 x 1, the scores for each class&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;correct_class_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# number of classes, e.g. 10&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;loss_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;xrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# iterate over all wrong classes&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;c&quot;&gt;# skip for the true class to only loop over incorrect classes&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# accumulate loss for the i-th example&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct_class_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_i&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;L_i_vectorized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  A faster half-vectorized implementation. half-vectorized
  refers to the fact that for a single example the implementation contains
  no for loops, but there is still one loop over the examples (outside this function)
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# compute the margins for all classes in one vector operation&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# on y-th position scores[y] - scores[y] canceled and gave delta. We want&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# to ignore the y-th position and only consider margin on max wrong class&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;loss_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;margins&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_i&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  fully-vectorized implementation :
  - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10)
  - y is array of integers specifying correct class (e.g. 50,000-D array)
  - W are weights (e.g. 10 x 3073)
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# evaluate loss over all examples in X without using any for loops&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# left as exercise to reader in the assignment&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;softmax分类器&quot;&gt;Softmax分类器&lt;/h3&gt;
&lt;p&gt;Softmax分类器可以理解为逻辑回归分类对多类问题的一般化归纳。保持评分函数不变，将评分视为每个分类未归一化的对数概率。折叶损失换为交叉熵损失(cross-entropy loss)，数据集的损失依然表示为损失值和正则化损失之和。交叉熵损失公式如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_i=-log(\frac{e^{f_{y_i}}}{\sum_j e^{f_j}})&lt;/script&gt;

&lt;p&gt;其中函数被称为&lt;strong&gt;softmax函数&lt;/strong&gt;，输入值是评分向量，函数对其进行压缩，输出为一个元素为0-1之间的向量，且所有元素之和为1。下面从几个视角对交叉熵损失进行解释：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;信息理论：&lt;/strong&gt;在信息论中，真实分布&lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt;与估计分布&lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt;之间的交叉熵定义为：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(p,q)=-\sum_x p(x) logq(x)&lt;/script&gt;

&lt;p&gt;比较这个函数与softmax损失函数，我们发现softmax函数是最小化估计分类概率&lt;script type=&quot;math/tex&quot;&gt;\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}&lt;/script&gt;与真实分布之间的交叉熵。（真实分布是一个除了真实位置是1其他都为0的向量）另外，交叉熵可以写作熵与相对熵（Kullback-Leibler divergence差异，衡量相同事件空间中两个概率分布的差异）的和：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(p,q)=H(p)+D_{K,L}(p||q)&lt;/script&gt;

&lt;p&gt;也就是最小化两个分布之间的相对熵，使得预测分布的概率密度都在正确分类上。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;概率论：&lt;/strong&gt;评分函数我们看作是没有归一化的对数概率：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(y_i|x_i,W)=\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}&lt;/script&gt;

&lt;p&gt;softmax函数将其转化为了归一化的概率分布，最小化正确分类的负对数概率相当于最大似然估计（MIE），而正则化部分&lt;script type=&quot;math/tex&quot;&gt;R(W)&lt;/script&gt;可以被看作权重矩阵W的高斯先验，那么这里做的就是最大后验估计（MAP）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;实践技巧：&lt;/strong&gt;在实际编程时，会遇到指数和过大的问题，所以要将数值进行归一化，也就是在分式的分子分母都乘以一个常熟C，使得数值计算更加稳定。通常我们取&lt;script type=&quot;math/tex&quot;&gt;logC=-max_j f_j&lt;/script&gt;，将向量&lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt;中的数值进行平移使得最大值为0。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}=\frac{e^{f_{y_i}}+logC}{\sum_j e^{f_j}+logC}&lt;/script&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;123&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;456&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;789&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 例子中有3个分类，每个评分的数值都很大&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 不妙：数值问题，可能导致数值爆炸&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 将f中的值平移到最大值为0：&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# f becomes [-666, -333, 0]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 现在OK了，将给出正确结果&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;对比svm与softmax&quot;&gt;对比SVM与Softmax&lt;/h3&gt;
&lt;p&gt;SVM给出是否是该分类的判断，而softmax给出了对于不同分类准确率的把握。而可能性分布的集中与离散程度由正则化参数&lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;决定。当正则化参数越大，那么权重W会被惩罚的越多，那么它的权重数值就会更小，而输出的概率分布就会更加均匀离散。&lt;/p&gt;

&lt;p&gt;另外，SVM在超过安全距离后就满足了，W此时就不再变化；而softmax对分数永远不会满意，总是可以对损失值进行最小化。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://cs231n.github.io/assets/svmvssoftmax.png&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;线性分类器的相关内容就是这些，后面将学习如何高效得到使损失值最小的参数，称为最优化过程。&lt;/p&gt;
</description>
        <pubDate>Mon, 26 Sep 2016 15:00:00 +0800</pubDate>
        <link>http://localhost:4000/course/2016/09/26/CS231n-Linear-Classification/</link>
        <guid isPermaLink="true">http://localhost:4000/course/2016/09/26/CS231n-Linear-Classification/</guid>
        
        <category>CS231n</category>
        
        
        <category>Course</category>
        
      </item>
    
      <item>
        <title>Light in the darkness</title>
        <description>&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://ww2.sinaimg.cn/large/a73af05fjw1f86vg8fqi9j21bf0zkne7.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;学校游泳池，依山傍水。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://ww4.sinaimg.cn/mw690/a73af05fjw1f86vga8q31j21bf0zkn2a.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;那天晚霞与航班齐飞。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://ww1.sinaimg.cn/mw690/a73af05fjw1f86vgchqirj21bf0zkqc7.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;学校的高尔夫练习场，晚上像灯塔伫立湖边。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;http://ww4.sinaimg.cn/mw690/a73af05fjw1f86vggotu8j20hs0dcgpa.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;学校与海边之间的湖 名曰若海&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://ww2.sinaimg.cn/mw690/a73af05fjw1f86vgk17dtj20zk1bfdmz.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;最后是本科时的好朋友猫咪名曰烧鸡，已会葛优躺。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://ww3.sinaimg.cn/mw690/a73af05fjw1f86vgn92qkj21bf0zkalm.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;还可以在跳台上打哈欠！&lt;/span&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;愿母校越来越好&lt;br /&gt;
谨遵校旨&lt;br /&gt;
&lt;strong&gt;振兴中华 永世勿忘&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Thu, 22 Sep 2016 22:11:00 +0800</pubDate>
        <link>http://localhost:4000/life/2016/09/22/Light-in-the-darkness/</link>
        <guid isPermaLink="true">http://localhost:4000/life/2016/09/22/Light-in-the-darkness/</guid>
        
        <category>photo</category>
        
        <category>memory</category>
        
        
        <category>Life</category>
        
      </item>
    
      <item>
        <title>My travel through hackathons</title>
        <description>&lt;p&gt;夜深了，我坐在宿舍的电脑旁，疲倦的敲完今天的最后一行代码，准备关机上床睡觉。还处在大三的我对Opencv充满了兴趣，还在自己研究这个新奇又实用的库。突然，“叮——”一声，邮箱来了一封邮件，&lt;em&gt;“中国最大的黑客马拉松——HackShanghai”&lt;/em&gt;，&lt;strong&gt;&lt;u&gt;黑客马拉松&lt;/u&gt;&lt;/strong&gt;是什么，是黑客们的集会吗？我重新打开浏览器，决定探个明白。&lt;/p&gt;

&lt;p&gt;“黑客马拉松概念源自美国，随着智能手机风行，黑客马拉松逐渐成为插件开发的主要形式：一群高手云集一堂，几十个小时里开发出一款插件，累了或坐或卧，现场休息，做完当场交作品，是世界上最酷的开发者狂欢。”百科上是这样解释的。在我看来，黑客松就是极客们的Party，在这里用短短的一两天进行头脑风暴，用自己的想法和技术改进生活甚至改变世界。看到这里，好奇心与兴趣充满了我的内心，我一扫倦意，想看看国外的hackathons上开发者和设计者们做出了什么样的杰作。&lt;/p&gt;

&lt;p&gt;世界上最大的黑客松是宾夕法尼亚大学的PennApps，现场提供了一些最新的智能硬件，全美感兴趣、会编程的学生皆可以参加，他们三五个人组队，在几十个小时里完成了自己有关健康、科技、经济和游戏等想法的项目，有的用Web展现，有的做成App，还有的做出了可以应用的硬件。&lt;/p&gt;

&lt;p&gt;面对这样有趣而又富有技术气息的别开生面的开发者集会，我迫不及待地写了application给HackShanghai，并成功的得到了参赛机会还有机票报销。就这样，我踏上了第一次黑客马拉松的旅途。&lt;/p&gt;

&lt;h3 id=&quot;初出茅庐&quot;&gt;初出茅庐&lt;/h3&gt;
&lt;p&gt;HackShanghai 2014由&lt;strong&gt;&lt;u&gt;上海纽约大学&lt;/u&gt;&lt;/strong&gt;举办，迎接我们register的是来自五湖四海的留学生，而来参赛的二百五十名同学也遍布五个大洲的大学，会场每个队伍一张长桌，整个会场被各种知名抑或是创业IT企业包围，可以随时去了解它们的最新技术和企业文化，更可以免费使用到它们所提供的智能硬件或API接口。比赛时间是24个小时，代码要求被提交到Gitcafe赞助商的托管网站上，在demo展示后，会有10个组被选中进入上台评比的阶段，再从它们当中选出最后的前三名，奖励非常丰厚。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://localhost:4000/img/post-hackathon-1.jpg&quot; alt=&quot;&quot; width=&quot;200%&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;比赛现场!&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;在比赛开始前，主办方提供了组队的时间，你可以在众多参赛者中找到你想要的开发者，也可以作为懂某个技术的开发者加入其他队伍当中。我与来自上海交通大学的高策和周嘉俊组队，想共同利用主办方提供的手势体感设备Leap Motion开发一套云端文件管理系统。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;基于手势识别的云端文件管理系统，顾名思义，就是模仿电影《钢铁侠》中Tony Stark酷炫的操作台，全凭手势即可完成各种工作。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们先进行了分工，我负责使用Leap Motion的JS接口与Javascript的文件管理系统相融合对接，实现前端的手势化操作，他们两个负责后台服务器和demo展示的设计。在文件管理系统中实现了文件的上传下载、文本与图片的预览和网页分享等功能。经过24小时的奋战，我们成功完成了前端与后端的代码，欣喜地与周围的队伍开始交流。来自加拿大的一位外国小哥提建议说可以做成chrome插件或者sublime插件，在办公室中如果要分享文档、代码等资源时只需要用手轻轻一滑就可以了，就像打乒乓球一样。所以我们同样写了实现此功能的两个插件，心满意足地去参加demo展示了。&lt;/p&gt;

&lt;p&gt;然而结果差强人意，我们并没有通过海选进入最后的前十名，我们走访了其他队伍，觉得我们的实现程度高，代码量大，创意也不差，为什么没有得到青睐呢？&lt;/p&gt;

&lt;p&gt;原因在于，我们做的是系统，而黑客马拉松更看重的是别出心裁的创意和酷炫的展示，代码要通过精彩的展示秀出来，而我们冗长而繁琐的系统很难给人有趣的感觉从而落败。尽管如此，我们还是因为做得个人体验好而被一位记者看中，我们的作品因此登上了上海日报、腾讯新闻、搜狐科技等媒体网站和报纸。而这第一次参加比赛见识到了来自各地高手的创意和代码能力，认识了一群好朋友，并清醒地懂得了在短时间内做出一个&lt;strong&gt;&lt;u&gt;可用、有趣又吸人眼球的产品&lt;/u&gt;&lt;/strong&gt;有多么重要。&lt;/p&gt;

&lt;h3 id=&quot;转战机器人马拉松&quot;&gt;转战机器人马拉松&lt;/h3&gt;
&lt;p&gt;第二次黑客马拉松，是一场别开生面的机器人马拉松，全球知名的人型机器人公司ALDEBARAN来到中国举办的第一场黑客松，而机器人黑客松已经成功在欧洲和美国举办了许多起。这种由企业举办的黑客马拉松往往有个主题或者题目，比如“饿了吗黑客马拉松”是处理刷单问题的，大众黑客马拉松是做智能车载应用的等，而这次机器人马拉松则必须使用机器人Nao来实现相关想法！&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Nao是在学术领域世界范围内运用最广泛的类人机器人。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Aldebaran Robotics公司将Nao的技术开放给所有的高等教育项目，并于2010年成立基金会支持在机器人及其应用领域的教学项目，曾于上海世博会展出。它提供了C++、Python和JS接口供开发者使用。价值几万元的机器人作为智能硬件给每个马拉松团队免费使用着实让人兴奋，而马拉松开始前则进行了一天的基本培训，对Nao中Unix系统的架构进行了详细解释。&lt;/p&gt;

&lt;p&gt;机器人Nao的开发中，ALDEBARAN公司开发了一套类似于G语言的编程模式，通过简单的连线定义其系统的架构，再对每一个模块用Python进行编程即可。如果要自己开发一些预定义的模块的话，则要通过修改Unix系统中的模块来实现。机器人有头上和胸前两个摄像头，预定义了人脸和标志识别的函数；机器人的几十个关节也就是步进电机可以用来转动来设计舞蹈等动作；脚底下的两个压力传感器用来调节其平衡。之前的马拉松中有人做了用于自闭症儿童的应用、机器人荡秋千（这是数学模型和控制算法的精准）和爬梯子等动作，实验时各种滑稽的摔倒让人啼笑皆非。&lt;/p&gt;

&lt;p&gt;这次我们的创意出奇，因为我在培训课的时候与一位音响公司老总交流过，他提出建议可以让Nao在博览会上做产品的推广和宣传。我想这是一个好的主意，但是对于不会编程的人来说太难了，找团队做的话呢开发成本又不低，定制化程度高。所以我想开发一套可以自定义的展示系统，人们只需要将PPT做好，每一页要让Nao说的话写好，再在每一页加几个动作就完成了。这样人人都可以使用我们的软件开发&lt;strong&gt;&lt;u&gt;定制化的机器人展示系统&lt;/u&gt;&lt;/strong&gt;，岂不是Nao非常好的应用！&lt;/p&gt;

&lt;p&gt;所以我设计了整个代码框架，一个控制Powerpoint的Win32程序，一个后台服务器同步机器人的动作和ppt的播放，然后将Nao要说的话和动作设计用我们web课程中接触到的“标记语言”融合，用标记语言的方式清楚的给定每一页ppt机器人要做的动作和要说的话。这次我们团队3个人相对熟悉都来自中山大学，分工为任伟晗师兄写Win32程序，陈钰设计机器人的演讲动作和标记语言格式，我来写后台服务器同步播放ppt的电脑和机器人Nao，所有代码和调试大概在18个小时左右完成。而结果也是获得了一等奖的好成绩，我们的“自动讲述人”应用得到了ALDEBARAN公司中国区总经理的高度评价，而那位音响系统的老总也邀请我们去了广交会，我们把黑客马拉松中的作品真正带到了现实应用当中，看着在博览会上演讲的Nao和下面的观众新奇开心的样子，我开始懂得黑客马拉松的真正意义所在。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://ww2.sinaimg.cn/large/a73af05fjw1esl2trp64fj218g0xcqfy.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;Nao and me!&lt;/span&gt;&lt;/p&gt;

&lt;h3 id=&quot;更大的舞台华科unique-hack-day&quot;&gt;更大的舞台——华科Unique Hack Day&lt;/h3&gt;
&lt;p&gt;广交会结束后，我又自己报名参加了&lt;strong&gt;&lt;u&gt;华中科技大学&lt;/u&gt;&lt;/strong&gt;的Unique Hack Day，这次的参与者与我第一次参加HackShanghai的选手有着很大的重叠，并有来自清华北大上交台大等名校高手。我作为已经参加过两届的黑客松选手，从很早就开始了筹划，我和同校的程序高手王钦和美女设计师一起，抱哈工大王潇雨的大腿在提前一个周就开始了讨论，最后我们决定做一个多人在线体感音乐游戏命名为&lt;strong&gt;&lt;u&gt;SwordDancer&lt;/u&gt;&lt;/strong&gt;，提前看好自己需要用到的编程技术，并开始学习。&lt;/p&gt;

&lt;p&gt;到达武汉后，迎接我们的不但是闷热的天气，还有好吃的热干面，吃饱喝足后比赛开始。我们所构想的游戏是这样的，两名玩家在自己的电脑前面玩同一个游戏，两个人通过技能来使对方的血量降低，就像拳皇一样，而技能的释放则类似于《节奏大师》的模式，根据音乐和游戏中的提示做出相应的手势即可放出相应的技能。玩家体感自然是用我熟悉的leap motion，前端的工作量非常大由王钦完成，而经验丰富的王潇雨则负责游戏引擎也就是后台，美女设计师负责提供图片切片设计和手势动作设计，力求让游戏的界面和操作都引人入胜。&lt;/p&gt;

&lt;p&gt;整个游戏包括了3个程序，一个前端JS web，一个由node js写的服务器引擎，和一个专门识别手势并发送相应手势代码给服务器的程序。在整个游戏做完后还有3个小时的时间，我们脑洞大开，又引入了一个真人版的概念，我们想让游戏更加有趣，就是屏幕中对战的玩家不再是动漫人物，而是自己，也许以后会有真人扫描的硬件就可以自动生成很多切片，而这里我们则自己拍摄照片并写入前端。在展示时，我们的“真人、在线、体感、音乐游戏”的概念深入人心，而demo展示时两位玩家玩得不亦乐乎，投影中两个真人的战斗配合音乐也十分有趣。我们成功击败各路豪强，获得第二名，8000元的奖金和一部智能钢琴也是让我们满载而归！&lt;/p&gt;

&lt;p&gt;这次马拉松给我的经验是，在生活中就要积累idea，很多想法记录下来，综合一下也许就可以借助马拉松的机会和队友一起完成自己的想法了。&lt;/p&gt;

&lt;h3 id=&quot;国际黑客松hack-ntu&quot;&gt;国际黑客松——Hack NTU&lt;/h3&gt;
&lt;p&gt;由于获得了Unique Hack Day的前三名，我们获得了去&lt;strong&gt;&lt;u&gt;台湾大学&lt;/u&gt;&lt;/strong&gt;参加黑客松的机票报销，于是我们3个开发者又加上一个朋友Roy一起前往台湾参加比赛。&lt;/p&gt;

&lt;p&gt;Hack NTU是我所见过最大的黑客马拉松，有来自世界各地的1000人参加，期间还有台北市市长出席参观，政府可谓非常重视。&lt;/p&gt;

&lt;p&gt;我们到达台湾后，与提前到达的来自北美的小哥们一起去酒吧聊天，并一起在台湾大学体育馆中居住官方提供的宿舍，他们很多新奇的想法和晚上睡觉前看书的习惯让我们感受到了文化的差异。&lt;/p&gt;

&lt;p&gt;这次比赛就在台湾大学体育馆举行，上面主场馆是千人比赛场馆，楼下的教室则是各个赞助公司和开发者的talk，有非常多有趣的话题和讨论，如果没有idea可以去楼下听。除了官方提供了本次黑客松的主题——Hack into city之外，众多赞助商提供了不同的悬赏主题，如果做悬赏主题的话则可以获得悬赏任务的奖励。我们走访了Microsoft、Intel等不同公司的展台，最终选定一个特殊的创业公司——Migo。Migo是一家刚刚成立2年的创业公司，主要业务是将Internet推广到不发达地区，比如东南亚再比如非洲，用低廉的价格推广慢速的网络。这次的悬赏问题则是解决菲律宾的问题，给出了菲律宾的人口、经济、交通、住房等信息，自己选定题目并实现。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;根据数据，菲律宾目前还在使用2G网络，由于3G基础设施硬件铺设费用高，人们只能用慢速的网络从而也就无法访问丰富的视频资源。我们想到，高速网络一般用于看视频听音乐，而他们所缺的正是一个是数据中心，如果我们以社区为单位做数据中心，由人力来周期更新数据中心的数据，那么很多事情都可以实现！这正是以时间换空间。我们选用了Intel Edison的开发版，搭建了一套CDN并提供了一套SDK，CDN为使用者提供了高速便捷的资源访问，SDK则为开发者Hack into developing country提供了可能，我们的数据分发虽然靠人力而且慢了一些，但在短期使用比铺设网络要价格低廉的多，而且搭建CDN高速便捷，是个很好的想法。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;&lt;u&gt;我们给这个项目起名叫做Running Bit，奔跑的比特！&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们如愿得到了Migo公司的悬赏——去菲律宾参观他们的海外公司，并因为使用Intel开发版还意外获得了Intel开发奖。&lt;/p&gt;

&lt;p&gt;这次黑客松更像是世界IT文化的交流，不同地区不同肤色的人们用代码书写着不同的未来，智慧城市的主题也更显得熠熠生辉了。&lt;/p&gt;

&lt;h3 id=&quot;本科的结束编程之美全国总决赛&quot;&gt;本科的结束——编程之美全国总决赛&lt;/h3&gt;
&lt;p&gt;到了即将毕业的时候，在这个炎热的五月，我迎来了本科阶段最后一场比赛——&lt;strong&gt;&lt;u&gt;编程之美全国总决赛&lt;/u&gt;&lt;/strong&gt;，巧合的是又在上海，正是我第一场黑客松比赛的地方。&lt;/p&gt;

&lt;p&gt;这次比赛由微软与IEEE联合举办，比赛地点在微软上海紫竹园区，比赛时间是24小时，不算是单纯的黑客马拉松，却是黑客马拉松的性质。这次我带领两个大神学弟，并与山东大学的美女设计师殷锟组队。随着题目的发布，我们选择了“智能相框”的题目：通过一段语音在图片库中找到想要的图片，属于内容较为限定形式比较开放的半开放题目。&lt;/p&gt;

&lt;p&gt;选题过后，作为队长我首先与三名队员进行技术讨论，确定了此题在我们技术范围内可以找到的应用点和创新点——_&lt;strong&gt;&lt;u&gt;匹配算法与手势识别&lt;/u&gt;&lt;/strong&gt;_的融入，之后迅速分配任务，明确每个人的职责，王钦负责前端和手势识别部分的构建，高逸斌负责后台服务器的逻辑和每个API接口的书写，美女设计师负责将想法可视化并提供网页前端的美工切片，我负责核心算法的模型训练和图片数据集的预处理，并充当产品经理的角色统筹决策。&lt;/p&gt;

&lt;p&gt;按照我们的系统设计流程，语音作为原始输入后通过微软语音识别接口转化为文字，之后我们使用一个官方提供的LUIS语义理解模型将文字转化为语义，这时我们就找到了语音指令当中的命令和特征标签，比如“找到上海拍摄的下雨的图片”中“找到图片”是命令而“上海”、“下雨”是特征标签。这里的特征标签会与图片库中每张图片的特征标签做对比匹配，从而找到准确的匹配图片。除了队友们负责的如何更友好的呈现外，我在算法上要做的主要工作就是匹配算法和图片的预处理。&lt;/p&gt;

&lt;p&gt;匹配算法决定了找到图像的准确率，经过询问专门做文本挖掘的朋友，我们选择了在这里非常适合应用的Word2Vec算法，这个算法是将词语转化为数学向量的一种算法，在K维的向量空间中，词语的语义信息更多地被提取了出来，从而可以度量两个词语间的相似程度，比如“动物”和“狗”，“牛排”和“刀叉”的相似度高，那么我们就可以更加精确而广泛地找到图片。我们使用维基百科中文数据进行训练，经过测试，模型对于生活词汇较为准确。&lt;/p&gt;

&lt;p&gt;图片预处理地目的则在于给图片贴特征标签，那么我们直接通过微软认知服务提供的图像识别接口，将图片识别出的置信度大于0.5的物品作为标签加到json形式下的数据库中，并手动添加具体人物与时间地点信息。&lt;/p&gt;

&lt;p&gt;经过一白天的努力，我们基本完成了每个部分的原生代码构建，在回酒店的车上我们商讨了如何结合并决定整夜奋战！负责前后端的两个学弟在努力地调试和对接，直到凌晨4点才完工，而我的模型依然在训练中，我在提前写好测试代码后也昏昏入睡，同房间的其它队同学也没有回来睡觉，直接去附近的上海交通大学闵行校区通宵编程去了，压力袭来，我们一张一弛，有条不紊。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://localhost:4000/img/post-hackathon-2.jpg&quot; alt=&quot;&quot; width=&quot;100%&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;程序框图!&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;第二天清晨，惊喜地看到模型训练结束，成功载入并查询相近词成功后，我兴奋地去找只睡了3个小时的学弟，将算法融入后布置了上午的任务，将Web前端的鼠标操作全部改成基于手势识别的操作！为了完成比赛所需的答辩文档与PPT，我转头投入到另一个问题中，如何更好更快地将我们的idea呈现给参观人员与大赛评委。&lt;/p&gt;

&lt;p&gt;首先，我们给作品起名为&lt;strong&gt;&lt;u&gt;“Percepicture”&lt;/u&gt;&lt;/strong&gt;意为感知的图片，通过语音与手势灵活智能地寻找和操控图片，紧接着设计师殷锟将她设计的系统流程图和用户UI图展示给我看，设计图美观而详细地介绍了整个流程，我急忙配图书写了简洁的介绍文档：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;基于Web前端和Python服务器所构建的“Percepicture”语音搜图系统，通过微软认知服务中的语音识别API和语言理解智能服务（LUIS）API将用户的语音通过理解、转化得到用户的意图。而图片库中的图片则是经过图像识别API进行预处理，将图片的特征信息提取出来。当系统将用户意图与图片库中的图片特征进行匹配就可以得到用户想要的图片了。在关键词匹配的算法方面，同学们创新地使用了word2vec深度学习模型。他们对图片的标签语料进行训练并把词语映射到高维向量空间中，将词语匹配过程转化成数学向量相似度计算。在当今的大数据时代，这既扩展了搜索的广度又加深了搜索的深度，从而提高了搜索的准确率。在UI方面，为了使交互更加友好同时符合展览应用场景，系统中植入了基于手势识别的体感操作，整个系统可以通过语音和体感两种方式进行控制，大大增强了趣味性和互动性。”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在跟美女设计师说明了ppt的制作顺序后，我急忙赶去学弟们一侧录制demo视频，视频中要测试和体现我们所说的一切功能，并让评委老师感觉到生动和有趣。&lt;/p&gt;

&lt;p&gt;紧张的编程阶段结束后，即将迎来的是demo展示会，我们队队员为了准备好demo不出bug甚至没有去吃午饭。demo展示中每个队伍一个展板一张桌子，来自微软的员工和外界媒体评审来一一参观，在此期间我还惊喜地遇到了去年在台湾大学参加HackNTU认识的廖教授，原来这次的外卡题就是廖老亲自出的题目。demo展示环节中，我们也走访参观了其它队伍的作品，来自北大、北邮、上交、复旦等各大学校的选手都尝试用不同的解决办法进行技术攻坚，遇到难题时相互启发找到了突破方案。而来自台湾大学的创意赛选手则非常擅于展示和表达，也给人留下深刻的印象；来自江南大学的创意赛选手在短时间内理解了作品别后的算法并做了清晰地阐述和表达，让人佩服……&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;http://ww1.sinaimg.cn/large/a73af05fgw1f47ypparobj20zk0qok11.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;团队合影!&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;最后的评选中，我们亮点鲜明、界面友好而实现度高的作品获得了来自大中华区各位评委的认可成功夺魁，我们通过创新的设计、明确的分工、不懈的编程和细致的合作创造了团队的力量，赢得了比赛，赢得了前往美国微软总部游学的机会！&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;从上海到上海，从一个新手到受到认可到比赛冠军，差别并不是得奖与否，而是比赛的体验和自己的心态。如果比赛中你实现了&lt;strong&gt;&lt;u&gt;自己的想法&lt;/u&gt;&lt;/strong&gt;，见识到了&lt;strong&gt;&lt;u&gt;大家头脑的风暴&lt;/u&gt;&lt;/strong&gt;，结识了一帮在五湖四海&lt;strong&gt;&lt;u&gt;共同奋斗的朋友&lt;/u&gt;&lt;/strong&gt;，那就足够了，不是吗？&lt;br /&gt;
                                                           ———后记&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Thu, 22 Sep 2016 22:11:00 +0800</pubDate>
        <link>http://localhost:4000/hackathon/2016/09/22/My-travel-through-hackthons/</link>
        <guid isPermaLink="true">http://localhost:4000/hackathon/2016/09/22/My-travel-through-hackthons/</guid>
        
        <category>Hackathons</category>
        
        
        <category>Hackathon</category>
        
      </item>
    
      <item>
        <title>Robot Nao Developing Story</title>
        <description>&lt;h2 class=&quot;section-heading&quot;&gt;Hello, Nao! &lt;/h2&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;骏马腾飞春来报，梅花绽放祝福道。转眼已是马年，期间做了些水水的项目，写了些水水的paper，重要的是家人团聚过大年。回来的第一个周，就来参加Nao的机器人创客马拉松。不同于之前参加的Hackathon，这次由于是基于特定机器人Nao开发，所以之前还有一个基础的培训。&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;人形机器人Nao是世界上最先进的人形机器人之一，在培训中，我们学习了其C++/Python的API，并简单的了解了其硬件设施，包括步进电机、传感器和处理设备。其复杂的传感设备和电机都可以通过编写参数来调节，为方便工程师和设计师，ALDEBARAN公司开发Choregraphe图形化编程界面，其语言类似Labview的G语言，由模块连接而成，而每个模块都可以通过修改Python代码改变其基础功能。&lt;/p&gt;

&lt;h2 class=&quot;section-heading&quot;&gt;Match and coding &lt;/h2&gt;
&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;基于特定的机器人，我们首先考虑了它的用途，基于其大小、形状和API特性，我们设计了一套用于presentation的自动化部署程序，即连接PC和Nao，用户只需要提供ppt和想要演讲的文字，Nao会帮助用户完成自动的展示。机器人的展示脱离了枯燥无味的风格，也不会受到人为因素的影响，其高逼格的特点使得发布会、演示甚至授课轻松有趣。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot;&gt;
    &lt;img class=&quot;img-responsive&quot; src=&quot;/img/Nao.jpg&quot; alt=&quot;&quot; /&gt;
&lt;/a&gt;
&lt;span class=&quot;caption text-muted&quot;&gt;Nao and me!&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;我们的作品幸运得在最后的评比中夺得一等奖，也是参加Hackathon的第一个名誉性成果，48小时的连续编程实属不易！&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;后续我们的作品在广交会（Canton Fair）中展出，为创锐科技公司的音响设备做了高大上的介绍和发布！&lt;/p&gt;
</description>
        <pubDate>Wed, 18 Mar 2015 17:47:00 +0800</pubDate>
        <link>http://localhost:4000/hackathon/2015/03/18/Nao-Robot-Develop-Story/</link>
        <guid isPermaLink="true">http://localhost:4000/hackathon/2015/03/18/Nao-Robot-Develop-Story/</guid>
        
        <category>Human-like robot</category>
        
        
        <category>Hackathon</category>
        
      </item>
    
  </channel>
</rss>


    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    <li>
                        <a href="http://www.renren.com/263506266/profile">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-renren fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="http://weibo.com/2805657695">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://twitter.com/Marsrocky">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://www.facebook.com/jianfei.yang.526">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li>
                        <a href="https://github.com/Marsrocky">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <p class="copyright text-muted">Copyright &copy; Marsrock 2018</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/clean-blog.min.js "></script>


</body>

</html>
